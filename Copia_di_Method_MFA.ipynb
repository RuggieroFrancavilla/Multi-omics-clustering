{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia di Method MFA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPyTgSiADfiq"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-fxRqzP0g8P"
      },
      "source": [
        "!pip install prince\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import prince\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score, confusion_matrix, adjusted_mutual_info_score, adjusted_rand_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# Import utils.py\n",
        "!gdown 'https://drive.google.com/uc?id=13I5w4WajPg6MObtLPQjxznm8w5hKlEY0' -O ./utils.py\n",
        "from utils import *\n",
        "\n",
        "#https://github.com/MaxHalford/prince\n",
        "#https://personal.utdallas.edu/~herve/Abdi-MFA2007-pretty.pdf\n",
        "#https://bmcgenomics.biomedcentral.com/track/pdf/10.1186/1471-2164-10-32.pdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re5VIPoI7Oks"
      },
      "source": [
        "# Synthetic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP04V5DDAGRN"
      },
      "source": [
        "Load omics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnI0U2v9AFx1"
      },
      "source": [
        "# Load dataset\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=12PArkc1RsOm2437mbysxRF4hQMddZOsc' -O ./mRNA.txt\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1aJkDF0ckxzY4vsnS53s-V89DdAnRVbPo' -O ./meth.txt\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1iS4u1SZH6r_Dvs7qRSKC444kc_bqmGhJ' -O ./prot.txt\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UtHj4BzBx5hnQkkklJ9ugU5ERjLhjx4W' -O ./clusters.txt\n",
        "\n",
        "ds = {}     # this will contain each omic\n",
        "omics = ['mRNA','meth','prot']\n",
        "for omic_name in omics:\n",
        "    path = omic_name + \".txt\"\n",
        "    ds[omic_name] = pd.read_csv(path, sep='\\t', index_col=0)\n",
        "    ds[omic_name].index.name = None\n",
        "    ds[omic_name] = ds[omic_name].T\n",
        "    # N.B.: the matrices have been transposed so that now we have samples as rows and features as columns\n",
        "\n",
        "\n",
        "y = pd.read_csv('clusters.txt', sep='\\t').set_index('subjects')    # this will contain the true cluster label of each sample\n",
        "true_cluster_labels_synthetic = y.values.reshape(y.shape[0])-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4OmUCnNAH5B"
      },
      "source": [
        "Pre-process omics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGWJFcSRJQN-"
      },
      "source": [
        "for omic in omics:\n",
        "    if omic == \"meth\":\n",
        "        mu = 0\n",
        "        sigma = 0.4\n",
        "\n",
        "    elif omic == \"prot\":\n",
        "        mu = 0\n",
        "        sigma = 4\n",
        "\n",
        "    else:\n",
        "        mu = 0\n",
        "        sigma = 4\n",
        "        \n",
        "    n_samples, n_features = ds[omic].shape\n",
        "\n",
        "    # Add salt & pepper noise\n",
        "    np.random.seed(42)   # fixed seed for reproducibility\n",
        "    noise = np.random.normal(mu, sigma, size=(n_samples, n_features))\n",
        "    p = 0.5 #0.8     # salt & pepper noise: add (gaussian) noise to a particolar feature of a particular sample with probability p\n",
        "    raveled_indices = np.random.choice(np.arange(n_samples*n_features), replace=False, size=int(n_samples*n_features*(1-p)))\n",
        "    indices = np.unravel_index(raveled_indices, (n_samples, n_features))\n",
        "    noise[indices] = 0\n",
        "\n",
        "    print(f\"Salt & pepper gaussian noise N({mu},{sigma**2}) is added to the {omic} dataset\")\n",
        "    ds[f'{omic}_noisy'] = ds[f'{omic}'] + noise\n",
        "\n",
        "\n",
        "\n",
        "    # Normalize omic\n",
        "    ds[f'{omic}_normalized'] = MinMaxScaler().fit_transform(ds[f'{omic}_noisy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1QK8SQSJQfz"
      },
      "source": [
        "Apply MFA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QAM1ybBJTsN"
      },
      "source": [
        "# Concatenate omics\n",
        "ds['early_integr'] = np.concatenate([ds[f\"{omic}_normalized\"] for omic in omics], axis=1)\n",
        "\n",
        "groups = {'omic1' : np.arange(0, ds['mRNA'].shape[1]),\n",
        "          'omic2' : np.arange(ds['mRNA'].shape[1], ds['mRNA'].shape[1]+ds['meth'].shape[1]),\n",
        "          'omic3' : np.arange(ds['mRNA'].shape[1]+ds['meth'].shape[1], ds['mRNA'].shape[1]+ds['meth'].shape[1]+ds['prot'].shape[1])\n",
        "          }\n",
        "\n",
        "mfa = prince.MFA(\n",
        "    groups=groups,\n",
        "    n_components=64,\n",
        "    n_iter=3,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='auto',\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "reduced_ds = mfa.fit_transform(pd.DataFrame(ds['early_integr']))    # (500,64)\n",
        "\n",
        "\n",
        "for k in range(2,11):\n",
        "    ##### Apply K-means\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    cluster_assignments = kmeans.fit_predict(reduced_ds)\n",
        "\n",
        "    # Perform a 2D PCA to visualize the dataset\n",
        "    pca = PCA(2)\n",
        "    principalComponents = pca.fit_transform(reduced_ds)\n",
        "    kmeans.cluster_centers_ = pca.transform(kmeans.cluster_centers_)\n",
        "\n",
        "    # Plot the clustered dataset\n",
        "    plot_2D_dataset(principalComponents, cluster_assignments, title='Dataset', caption=f'{k} predicted clusters')\n",
        "    plot_2D_dataset(principalComponents, true_cluster_labels_synthetic, title='Dataset', caption=f'true clusters')\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plot_confusion_matrix(true_cluster_labels_synthetic, cluster_assignments)\n",
        "\n",
        "    # Compute silhouette\n",
        "    print(silhouette_score(reduced_ds, cluster_assignments))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOiAIbYf7P37"
      },
      "source": [
        "# Lung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtoyjXOr7S6I"
      },
      "source": [
        "Load omics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmLJBhJg7T8i"
      },
      "source": [
        "# Load dataset\n",
        "!gdown 'https://drive.google.com/uc?id=1kNQxRoCs6TIGVzdlpEpUkAqx8FyoSrsi' -O ./mRNA.txt\n",
        "!gdown 'https://drive.google.com/uc?id=16V4tY8GeCUemOrf_KBqJwdixrQYZmFHv' -O ./miRNA.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1UuCNcXbxHS1lW3bRkixsbo77xIFsWxIG' -O ./meth.txt\n",
        "# Batch effect corrected with combat\n",
        "# Only autosomic genes are kept; duplicated features were removed before applying combat\n",
        "!gdown 'https://drive.google.com/uc?id=1RT1EiQCj19gGD8bYr0UBjxvUPl8473FX' -O ./cnv.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1t1rTrZNVHqZRo_F0YA0heD3WbvijHox7' -O ./clusters.txt\n",
        "\n",
        "ds = {}     # this will contain each omic\n",
        "omics = ['mRNA','miRNA','meth','cnv']\n",
        "for omic_name in omics:\n",
        "    path = omic_name + \".txt\"\n",
        "    if omic_name not in ds:\n",
        "        ds[omic_name] = pd.read_csv(path, sep='\\t', index_col=0)\n",
        "\n",
        "y = pd.read_csv('clusters.txt', sep='\\t', index_col=0)\n",
        "true_cluster_labels_lung = y.values.reshape(y.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6opjspt8tFk"
      },
      "source": [
        "Pre-process omics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfIGXt_L8mvn"
      },
      "source": [
        "# mRNA\n",
        "# Keep only protein coding genes\n",
        "# NB: the file idx_mRNA_prot_cod.txt, containing the protein coding genes of the\n",
        "# human genome, has been obtained in the colab notebook 'Find protein coding genes'\n",
        "if not os.path.exists(\"./idx_mRNA_prot_cod_lung.txt\"):\n",
        "    !gdown 'https://drive.google.com/uc?id=1i6lXPIh60BtCF-ujfaqf4WrvWM4XMvNF' -O ./idx_mRNA_prot_cod_lung.txt\n",
        "\n",
        "idx_mRNA_prot_cod = pd.read_csv('idx_mRNA_prot_cod_lung.txt')\n",
        "idx_mRNA_prot_cod = idx_mRNA_prot_cod['idx'].values\n",
        "\n",
        "ds['mRNA'] = ds['mRNA'].iloc[:, idx_mRNA_prot_cod]\n",
        "\n",
        "# Delete genes with a zero expression value across all the samples\n",
        "ds['mRNA'] = ds['mRNA'].loc[:, (ds['mRNA'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize mRNA with MinMax Scaler\n",
        "ds['mRNA_normalized'] = MinMaxScaler().fit_transform(ds['mRNA'].values)\n",
        "\n",
        "\n",
        "\n",
        "# miRNA\n",
        "# Delete sequences with a zero expression value across all the samples\n",
        "ds['miRNA'] = ds['miRNA'].loc[:, (ds['miRNA'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize with log2 normalization\n",
        "ds['miRNA'] = np.log(ds['miRNA'] + 1) / np.log(2)\n",
        "\n",
        "# Normalize with MinMaxScaler\n",
        "ds['miRNA_normalized'] = MinMaxScaler().fit_transform(ds['miRNA'].values)\n",
        "\n",
        "\n",
        "\n",
        "# meth\n",
        "# Delete sequences with a zero expression value across all the samples\n",
        "ds['meth'] = ds['meth'].loc[:, (ds['meth'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize with MinMaxScaler\n",
        "ds['meth_normalized'] = MinMaxScaler().fit_transform(ds['meth'].values)\n",
        "\n",
        "\n",
        "\n",
        "# cnv\n",
        "# Normalize with MinMaxScaler\n",
        "ds['cnv_normalized'] = MinMaxScaler().fit_transform(ds['cnv'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBQMCS0J_xUg"
      },
      "source": [
        "Apply MFA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTgLmPKO_ySq"
      },
      "source": [
        "# Concatenate omics\n",
        "ds['early_integr'] = np.concatenate([ds[f\"{omic}_normalized\"] for omic in omics], axis=1)\n",
        "\n",
        "groups = {'omic1' : np.arange(0, ds['mRNA'].shape[1]),\n",
        "          'omic2' : np.arange(ds['mRNA'].shape[1], ds['mRNA'].shape[1]+ds['miRNA'].shape[1]),\n",
        "          'omic3' : np.arange(ds['mRNA'].shape[1]+ds['miRNA'].shape[1], ds['mRNA'].shape[1]+ds['miRNA'].shape[1]+ds['meth'].shape[1]),\n",
        "          'omic4' : np.arange(ds['mRNA'].shape[1]+ds['miRNA'].shape[1]+ds['meth'].shape[1], ds['mRNA'].shape[1]+ds['miRNA'].shape[1]+ds['meth'].shape[1]+ds['cnv'].shape[1])\n",
        "          }\n",
        "\n",
        "mfa = prince.MFA(\n",
        "    groups=groups,\n",
        "    n_components=64,\n",
        "    n_iter=3,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='auto',\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "reduced_ds = mfa.fit_transform(pd.DataFrame(ds['early_integr']))    # (783,64)\n",
        "\n",
        "\n",
        "for k in range(2,11):\n",
        "    ##### Apply K-means\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    cluster_assignments = kmeans.fit_predict(reduced_ds)\n",
        "\n",
        "    # Perform a 2D PCA to visualize the dataset\n",
        "    pca = PCA(2)\n",
        "    principalComponents = pca.fit_transform(reduced_ds)\n",
        "    kmeans.cluster_centers_ = pca.transform(kmeans.cluster_centers_)\n",
        "\n",
        "    # Plot the clustered dataset\n",
        "    plot_2D_dataset(principalComponents, cluster_assignments, title='Dataset', caption=f'{k} predicted clusters')\n",
        "    plot_2D_dataset(principalComponents, true_cluster_labels_lung, title='Dataset', caption=f'true clusters')\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plot_confusion_matrix(true_cluster_labels_lung, cluster_assignments)\n",
        "\n",
        "    # Compute silhouette\n",
        "    print(silhouette_score(reduced_ds, cluster_assignments))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf6fORUL7RLq"
      },
      "source": [
        "# Kidney"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JmIlmnrI4R4"
      },
      "source": [
        "Load omics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_6NjRsNAE_l"
      },
      "source": [
        "# Load dataset\n",
        "!gdown 'https://drive.google.com/uc?id=1i1do_UTzwXzPVIDDmYSFJEholK2Mp8g_' -O ./mRNA.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1liKeOBKjnbCi1CIjcOPA3Zxv2fRzCfa2' -O ./miRNA.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1qr9joY0bAVDLvjWsKF5xf3CaRolBu-mP' -O ./meth.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1R-U2iDgM4oEyzNRfBIA2kXMbKw_s0QtI' -O ./clusters.txt\n",
        "\n",
        "ds = {}     # this will contain each omic\n",
        "omics = ['mRNA','miRNA','meth']\n",
        "for omic_name in omics:\n",
        "    path = omic_name + \".txt\"\n",
        "    if omic_name not in ds:\n",
        "        ds[omic_name] = pd.read_csv(path, sep='\\t', index_col=0)\n",
        "\n",
        "y = pd.read_csv('clusters.txt', sep='\\t', index_col=0)\n",
        "true_cluster_labels_kidney = y.values.reshape(y.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bkLVVXPI5W9"
      },
      "source": [
        "Pre-process omics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrTRO7ePI6JI"
      },
      "source": [
        "# mRNA\n",
        "# Keep only protein coding genes\n",
        "# NB: the file idx_mRNA_prot_cod.txt, containing the protein coding genes of the\n",
        "# human genome, has been obtained in the colab notebook 'Find protein coding genes'\n",
        "if not os.path.exists(\"./idx_mRNA_prot_cod_kidney.txt\"):\n",
        "    !gdown 'https://drive.google.com/uc?id=1Pi4u8y_YAc2tmOWZYaeLn9wGdzu4cFC5' -O ./idx_mRNA_prot_cod_kidney.txt\n",
        "\n",
        "idx_mRNA_prot_cod = pd.read_csv('idx_mRNA_prot_cod_kidney.txt')\n",
        "idx_mRNA_prot_cod = idx_mRNA_prot_cod['idx'].values\n",
        "\n",
        "ds['mRNA'] = ds['mRNA'].iloc[:, idx_mRNA_prot_cod]\n",
        "\n",
        "# Delete genes with a zero expression value across all the samples\n",
        "ds['mRNA'] = ds['mRNA'].loc[:, (ds['mRNA'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize mRNA with MinMax Scaler\n",
        "ds['mRNA_normalized'] = MinMaxScaler().fit_transform(ds['mRNA'].values)\n",
        "\n",
        "\n",
        "\n",
        "# miRNA\n",
        "# Delete sequences with a zero expression value across all the samples\n",
        "ds['miRNA'] = ds['miRNA'].loc[:, (ds['miRNA'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize with log2 normalization\n",
        "ds['miRNA'] = np.log(ds['miRNA'] + 1) / np.log(2)\n",
        "\n",
        "# Normalize with MinMaxScaler\n",
        "ds['miRNA_normalized'] = MinMaxScaler().fit_transform(ds['miRNA'].values)\n",
        "\n",
        "\n",
        "\n",
        "# meth\n",
        "# Delete sequences with a zero expression value across all the samples\n",
        "ds['meth'] = ds['meth'].loc[:, (ds['meth'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize with MinMaxScaler\n",
        "ds['meth_normalized'] = MinMaxScaler().fit_transform(ds['meth'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTAG5QZxI6Y3"
      },
      "source": [
        "Apply MFA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-xoiBdCI7Ej"
      },
      "source": [
        "# Concatenate omics\n",
        "ds['early_integr'] = np.concatenate([ds[f\"{omic}_normalized\"] for omic in omics], axis=1)\n",
        "\n",
        "groups = {'omic1' : np.arange(0, ds['mRNA'].shape[1]),\n",
        "          'omic2' : np.arange(ds['mRNA'].shape[1], ds['mRNA'].shape[1]+ds['miRNA'].shape[1]),\n",
        "          'omic3' : np.arange(ds['mRNA'].shape[1]+ds['miRNA'].shape[1], ds['mRNA'].shape[1]+ds['miRNA'].shape[1]+ds['meth'].shape[1])\n",
        "          }\n",
        "\n",
        "mfa = prince.MFA(\n",
        "    groups=groups,\n",
        "    n_components=64,\n",
        "    n_iter=3,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='auto',\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "reduced_ds = mfa.fit_transform(pd.DataFrame(ds['early_integr']))    # (650,64)\n",
        "\n",
        "\n",
        "for k in range(2,11):\n",
        "    ##### Apply K-means\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    cluster_assignments = kmeans.fit_predict(reduced_ds)\n",
        "\n",
        "    # Perform a 2D PCA to visualize the dataset\n",
        "    pca = PCA(2)\n",
        "    principalComponents = pca.fit_transform(reduced_ds)\n",
        "    kmeans.cluster_centers_ = pca.transform(kmeans.cluster_centers_)\n",
        "\n",
        "    # Plot the clustered dataset\n",
        "    plot_2D_dataset(principalComponents, cluster_assignments, title='Dataset', caption=f'{k} predicted clusters')\n",
        "    plot_2D_dataset(principalComponents, true_cluster_labels_kidney, title='Dataset', caption=f'true clusters')\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plot_confusion_matrix(true_cluster_labels_kidney, cluster_assignments)\n",
        "\n",
        "    # Compute silhouette\n",
        "    print(silhouette_score(reduced_ds, cluster_assignments))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}