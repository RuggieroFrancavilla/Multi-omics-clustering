{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Copia di Method SNF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "present-optimum"
      },
      "source": [
        "!pip install snfpy\n",
        "import snf\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import spectral_clustering\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.metrics import silhouette_score, confusion_matrix, adjusted_mutual_info_score, adjusted_rand_score, silhouette_samples\n",
        "\n",
        "# Import utils.py\n",
        "!gdown 'https://drive.google.com/uc?id=13I5w4WajPg6MObtLPQjxznm8w5hKlEY0' -O ./utils.py\n",
        "from utils import *"
      ],
      "id": "present-optimum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hB5zniinepW"
      },
      "source": [
        "# Synthetic"
      ],
      "id": "7hB5zniinepW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6nNfLPRnihz"
      },
      "source": [
        "Load omics"
      ],
      "id": "b6nNfLPRnihz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_EDCjwVncDe"
      },
      "source": [
        "# Load dataset\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=12PArkc1RsOm2437mbysxRF4hQMddZOsc' -O ./mRNA.txt\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1aJkDF0ckxzY4vsnS53s-V89DdAnRVbPo' -O ./meth.txt\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1iS4u1SZH6r_Dvs7qRSKC444kc_bqmGhJ' -O ./prot.txt\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UtHj4BzBx5hnQkkklJ9ugU5ERjLhjx4W' -O ./clusters.txt\n",
        "\n",
        "ds = {}     # this will contain each omic\n",
        "omics = ['mRNA','meth','prot']\n",
        "for omic_name in omics:\n",
        "    path = omic_name + \".txt\"\n",
        "    ds[omic_name] = pd.read_csv(path, sep='\\t', index_col=0)\n",
        "    ds[omic_name].index.name = None\n",
        "    ds[omic_name] = ds[omic_name].T\n",
        "    # N.B.: the matrices have been transposed so that now we have samples as rows and features as columns\n",
        "\n",
        "\n",
        "y = pd.read_csv('clusters.txt', sep='\\t').set_index('subjects')    # this will contain the true cluster label of each sample\n",
        "true_cluster_labels_synthetic = y.values.reshape(y.shape[0])-1"
      ],
      "id": "F_EDCjwVncDe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcAO9FW8noUU"
      },
      "source": [
        "Pre-process omics"
      ],
      "id": "xcAO9FW8noUU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLcuf-6TnsuM"
      },
      "source": [
        "for omic in omics:\n",
        "    if omic == \"meth\":\n",
        "        mu = 0 #0.1\n",
        "        sigma = 0.4 # 0.4\n",
        "\n",
        "    elif omic == \"prot\":\n",
        "        mu = 0\n",
        "        sigma = 4 # 4\n",
        "\n",
        "    else:\n",
        "        mu = 0\n",
        "        sigma = 4 # 4\n",
        "        \n",
        "    n_samples, n_features = ds[omic].shape\n",
        "\n",
        "    # Add salt & pepper noise\n",
        "    np.random.seed(42)   # fixed seed for reproducibility\n",
        "    noise = np.random.normal(mu, sigma, size=(n_samples, n_features))\n",
        "    p = 0.5 #0.8     # salt & pepper noise: add (gaussian) noise to a particolar feature of a particular sample with probability p\n",
        "    raveled_indices = np.random.choice(np.arange(n_samples*n_features), replace=False, size=int(n_samples*n_features*(1-p)))\n",
        "    indices = np.unravel_index(raveled_indices, (n_samples, n_features))\n",
        "    noise[indices] = 0\n",
        "\n",
        "    print(f\"Salt & pepper gaussian noise N({mu},{sigma**2}) is added to the {omic} dataset\")\n",
        "    ds[f'{omic}_noisy'] = ds[f'{omic}'] + noise\n",
        "\n",
        "\n",
        "\n",
        "    # Normalize omic\n",
        "    ds[f'{omic}_normalized'] = MinMaxScaler().fit_transform(ds[f'{omic}_noisy'])\n"
      ],
      "id": "pLcuf-6TnsuM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnxzuK3en4QX"
      },
      "source": [
        "Apply SNF"
      ],
      "id": "xnxzuK3en4QX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgk49a-Hn268"
      },
      "source": [
        "# Concatenate omics\n",
        "ds['early_integr'] = [ds[f\"{omic}_normalized\"] for omic in omics]\n",
        "\n",
        "affinity_networks = snf.make_affinity(ds['early_integr'], metric='euclidean', K=5, mu=0.5)  # these are the W matrices for each omic\n",
        "fused_network = snf.snf(affinity_networks, K=5) # overall status matrix P^(c)\n",
        "best, _ = snf.get_n_clusters(fused_network)    # optimal n. of clusters estimated via an eigengap approach\n",
        "print(best)\n",
        "cluster_assignments = spectral_clustering(fused_network, n_clusters=best)\n",
        "\n",
        "ds['early_integr'] = np.concatenate([ds[f\"{omic}_normalized\"] for omic in omics], axis=1)\n",
        "\n",
        "# Perform a 2D PCA to visualize the dataset\n",
        "pca = PCA(2)\n",
        "principalComponents = pca.fit_transform(ds['early_integr'])\n",
        "\n",
        "# Plot the clustered dataset\n",
        "plot_2D_dataset(principalComponents, cluster_assignments, title='Dataset', caption=f'{best} predicted clusters')\n",
        "plot_2D_dataset(principalComponents, true_cluster_labels_synthetic, title='Dataset', caption=f'true clusters')\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix(true_cluster_labels_synthetic, cluster_assignments)\n",
        "\n",
        "# Compute silhouette\n",
        "print(silhouette_score(ds['early_integr'], cluster_assignments))"
      ],
      "id": "Rgk49a-Hn268",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehrFleXGosqn"
      },
      "source": [
        "# Lung"
      ],
      "id": "ehrFleXGosqn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLPQ0OqWoyZ9"
      },
      "source": [
        "Load omics"
      ],
      "id": "OLPQ0OqWoyZ9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TypnVHxHo3Iz"
      },
      "source": [
        "# Load dataset\n",
        "!gdown 'https://drive.google.com/uc?id=1kNQxRoCs6TIGVzdlpEpUkAqx8FyoSrsi' -O ./mRNA.txt\n",
        "!gdown 'https://drive.google.com/uc?id=16V4tY8GeCUemOrf_KBqJwdixrQYZmFHv' -O ./miRNA.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1UuCNcXbxHS1lW3bRkixsbo77xIFsWxIG' -O ./meth.txt\n",
        "# Batch effect corrected with combat\n",
        "# Only autosomic genes are kept; duplicated features were removed before applying combat\n",
        "!gdown 'https://drive.google.com/uc?id=1RT1EiQCj19gGD8bYr0UBjxvUPl8473FX' -O ./cnv.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1t1rTrZNVHqZRo_F0YA0heD3WbvijHox7' -O ./clusters.txt\n",
        "\n",
        "ds = {}     # this will contain each omic\n",
        "omics = ['mRNA','miRNA','meth','cnv']\n",
        "for omic_name in omics:\n",
        "    path = omic_name + \".txt\"\n",
        "    if omic_name not in ds:\n",
        "        ds[omic_name] = pd.read_csv(path, sep='\\t', index_col=0)\n",
        "\n",
        "y = pd.read_csv('clusters.txt', sep='\\t', index_col=0)\n",
        "true_cluster_labels_lung = y.values.reshape(y.shape[0])"
      ],
      "id": "TypnVHxHo3Iz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqsbkR7LpTge"
      },
      "source": [
        "Pre-process omics"
      ],
      "id": "YqsbkR7LpTge"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stXuzKYppFgu"
      },
      "source": [
        "# mRNA\n",
        "# Keep only protein coding genes\n",
        "# NB: the file idx_mRNA_prot_cod.txt, containing the protein coding genes of the\n",
        "# human genome, has been obtained in the colab notebook 'Find protein coding genes'\n",
        "if not os.path.exists(\"./idx_mRNA_prot_cod_lung.txt\"):\n",
        "    !gdown 'https://drive.google.com/uc?id=1i6lXPIh60BtCF-ujfaqf4WrvWM4XMvNF' -O ./idx_mRNA_prot_cod_lung.txt\n",
        "\n",
        "idx_mRNA_prot_cod = pd.read_csv('idx_mRNA_prot_cod_lung.txt')\n",
        "idx_mRNA_prot_cod = idx_mRNA_prot_cod['idx'].values\n",
        "\n",
        "ds['mRNA'] = ds['mRNA'].iloc[:, idx_mRNA_prot_cod]\n",
        "\n",
        "# Delete genes with a zero expression value across all the samples\n",
        "ds['mRNA'] = ds['mRNA'].loc[:, (ds['mRNA'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize mRNA with MinMax Scaler\n",
        "ds['mRNA_normalized'] = MinMaxScaler().fit_transform(ds['mRNA'].values)\n",
        "\n",
        "\n",
        "\n",
        "# miRNA\n",
        "# Delete sequences with a zero expression value across all the samples\n",
        "ds['miRNA'] = ds['miRNA'].loc[:, (ds['miRNA'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize with log2 normalization\n",
        "ds['miRNA'] = np.log(ds['miRNA'] + 1) / np.log(2)\n",
        "\n",
        "# Normalize with MinMaxScaler\n",
        "ds['miRNA_normalized'] = MinMaxScaler().fit_transform(ds['miRNA'].values)\n",
        "\n",
        "\n",
        "\n",
        "# meth\n",
        "# Delete sequences with a zero expression value across all the samples\n",
        "ds['meth'] = ds['meth'].loc[:, (ds['meth'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize with MinMaxScaler\n",
        "ds['meth_normalized'] = MinMaxScaler().fit_transform(ds['meth'].values)\n",
        "\n",
        "\n",
        "\n",
        "# cnv\n",
        "# Normalize with MinMaxScaler\n",
        "ds['cnv_normalized'] = MinMaxScaler().fit_transform(ds['cnv'].values)"
      ],
      "id": "stXuzKYppFgu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oWMOHzkphU-"
      },
      "source": [
        "Apply SNF"
      ],
      "id": "7oWMOHzkphU-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYNyKCYqpmVE"
      },
      "source": [
        "# Concatenate omics\n",
        "ds['early_integr'] = [ds[f\"{omic}_normalized\"] for omic in omics]\n",
        "\n",
        "affinity_networks = snf.make_affinity(ds['early_integr'], metric='euclidean', K=5, mu=0.5)\n",
        "fused_network = snf.snf(affinity_networks, K=5)\n",
        "best, second = snf.get_n_clusters(fused_network)\n",
        "print(best)\n",
        "cluster_assignments = spectral_clustering(fused_network, n_clusters=best)\n",
        "\n",
        "ds['early_integr'] = np.concatenate([ds[f\"{omic}_normalized\"] for omic in omics], axis=1)\n",
        "\n",
        "# Perform a 2D PCA to visualize the dataset\n",
        "pca = PCA(2)\n",
        "principalComponents = pca.fit_transform(ds['early_integr'])\n",
        "\n",
        "# Plot the clustered dataset\n",
        "plot_2D_dataset(principalComponents, cluster_assignments, title='Dataset', caption=f'{best} predicted clusters')\n",
        "plot_2D_dataset(principalComponents, true_cluster_labels_lung, title='Dataset', caption=f'true clusters')\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix(true_cluster_labels_lung, cluster_assignments)\n",
        "\n",
        "# Compute silhouette\n",
        "print(silhouette_score(ds['early_integr'], cluster_assignments))"
      ],
      "id": "BYNyKCYqpmVE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBDhCT8gpsCD"
      },
      "source": [
        "#Kidney"
      ],
      "id": "dBDhCT8gpsCD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipxO4NbfqBbv"
      },
      "source": [
        "Load omics"
      ],
      "id": "ipxO4NbfqBbv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-Cy4KUUprfY"
      },
      "source": [
        "# Load dataset\n",
        "!gdown 'https://drive.google.com/uc?id=1i1do_UTzwXzPVIDDmYSFJEholK2Mp8g_' -O ./mRNA.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1liKeOBKjnbCi1CIjcOPA3Zxv2fRzCfa2' -O ./miRNA.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1qr9joY0bAVDLvjWsKF5xf3CaRolBu-mP' -O ./meth.txt\n",
        "!gdown 'https://drive.google.com/uc?id=1R-U2iDgM4oEyzNRfBIA2kXMbKw_s0QtI' -O ./clusters.txt\n",
        "\n",
        "ds = {}     # this will contain each omic\n",
        "omics = ['mRNA','miRNA','meth']\n",
        "for omic_name in omics:\n",
        "    path = omic_name + \".txt\"\n",
        "    if omic_name not in ds:\n",
        "        ds[omic_name] = pd.read_csv(path, sep='\\t', index_col=0)\n",
        "\n",
        "y = pd.read_csv('clusters.txt', sep='\\t', index_col=0)\n",
        "true_cluster_labels_kidney = y.values.reshape(y.shape[0])"
      ],
      "id": "p-Cy4KUUprfY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emehKNIfpvnf"
      },
      "source": [
        "Pre-process omics"
      ],
      "id": "emehKNIfpvnf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScLpeQ71pwBO"
      },
      "source": [
        "# mRNA\n",
        "# Keep only protein coding genes\n",
        "# NB: the file idx_mRNA_prot_cod.txt, containing the protein coding genes of the\n",
        "# human genome, has been obtained in the colab notebook 'Find protein coding genes'\n",
        "if not os.path.exists(\"./idx_mRNA_prot_cod_kidney.txt\"):\n",
        "    !gdown 'https://drive.google.com/uc?id=1Pi4u8y_YAc2tmOWZYaeLn9wGdzu4cFC5' -O ./idx_mRNA_prot_cod_kidney.txt\n",
        "\n",
        "idx_mRNA_prot_cod = pd.read_csv('idx_mRNA_prot_cod_kidney.txt')\n",
        "idx_mRNA_prot_cod = idx_mRNA_prot_cod['idx'].values\n",
        "\n",
        "ds['mRNA'] = ds['mRNA'].iloc[:, idx_mRNA_prot_cod]\n",
        "\n",
        "# Delete genes with a zero expression value across all the samples\n",
        "ds['mRNA'] = ds['mRNA'].loc[:, (ds['mRNA'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize mRNA with MinMax Scaler\n",
        "ds['mRNA_normalized'] = MinMaxScaler().fit_transform(ds['mRNA'].values)\n",
        "\n",
        "\n",
        "\n",
        "# miRNA\n",
        "# Delete sequences with a zero expression value across all the samples\n",
        "ds['miRNA'] = ds['miRNA'].loc[:, (ds['miRNA'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize with log2 normalization\n",
        "ds['miRNA'] = np.log(ds['miRNA'] + 1) / np.log(2)\n",
        "\n",
        "# Normalize with MinMaxScaler\n",
        "ds['miRNA_normalized'] = MinMaxScaler().fit_transform(ds['miRNA'].values)\n",
        "\n",
        "\n",
        "\n",
        "# meth\n",
        "# Delete sequences with a zero expression value across all the samples\n",
        "ds['meth'] = ds['meth'].loc[:, (ds['meth'] != 0).any(axis=0)]\n",
        "\n",
        "# Normalize with MinMaxScaler\n",
        "ds['meth_normalized'] = MinMaxScaler().fit_transform(ds['meth'].values)"
      ],
      "id": "ScLpeQ71pwBO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO8T_W3kp2vp"
      },
      "source": [
        "Apply SNF"
      ],
      "id": "MO8T_W3kp2vp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52lQ4anyp1MK"
      },
      "source": [
        "# Concatenate omics\n",
        "ds['early_integr'] = [ds[f\"{omic}_normalized\"] for omic in omics]\n",
        "\n",
        "affinity_networks = snf.make_affinity(ds['early_integr'], metric='euclidean', K=5, mu=0.5)\n",
        "fused_network = snf.snf(affinity_networks, K=5)\n",
        "best, second = snf.get_n_clusters(fused_network)\n",
        "print(best)\n",
        "cluster_assignments = spectral_clustering(fused_network, n_clusters=best)\n",
        "\n",
        "ds['early_integr'] = np.concatenate([ds[f\"{omic}_normalized\"] for omic in omics], axis=1)\n",
        "\n",
        "# Perform a 2D PCA to visualize the dataset\n",
        "pca = PCA(2)\n",
        "principalComponents = pca.fit_transform(ds['early_integr'])\n",
        "\n",
        "# Plot the clustered dataset\n",
        "plot_2D_dataset(principalComponents, cluster_assignments, title='Dataset', caption=f'{best} predicted clusters')\n",
        "plot_2D_dataset(principalComponents, true_cluster_labels_kidney, title='Dataset', caption=f'true clusters')\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix(true_cluster_labels_kidney, cluster_assignments)\n",
        "\n",
        "# Compute silhouette\n",
        "print(silhouette_score(ds['early_integr'], cluster_assignments))"
      ],
      "id": "52lQ4anyp1MK",
      "execution_count": null,
      "outputs": []
    }
  ]
}
